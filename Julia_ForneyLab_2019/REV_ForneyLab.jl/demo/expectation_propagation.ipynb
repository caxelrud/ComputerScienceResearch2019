{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Propagation\n",
    "\n",
    "ForneyLab comes with support for expectation propagation (EP). In this demo we illustrate EP in the context of state-estimation in a linear state-space model that combines a Gaussian state-evolution model with a discrete observation model. Here, the probit function links continuous variable `x_t` with the discrete variable `y_t`. The model is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "    u &= 0.1\\\\\n",
    "    x_0 &\\sim \\mathcal{N}(0, 100)\\\\\n",
    "    x_t &\\sim \\mathcal{N}(x_{t-1} + u, 0.01)\\\\\n",
    "    y_t &\\sim \\mathcal{B}er(\\Phi(x_t))\n",
    "\\end{align*}\n",
    "\n",
    "The FFG representation of this model consists of a concatenation of the following sections (one per timestep):\n",
    "\n",
    "```\n",
    "              (u)   (0.01)\n",
    "               |      |\n",
    "               v      v\n",
    "(x_t_min) ---> + --->[N]---> = ---> (x_t)\n",
    "                             |\n",
    "                            [Φ]\n",
    "                             | \n",
    "                           (y_t)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SpecialFunctions\n",
    "using Random\n",
    "# Generate data set\n",
    "\n",
    "Random.seed!(123)\n",
    "n_samples = 40\n",
    "Φ(x) = 0.5 + 0.5*erf.(x./sqrt(2))\n",
    "\n",
    "u_data = 0.1\n",
    "x_data = []\n",
    "y_data = []\n",
    "x_prev = -2.0\n",
    "for t=1:n_samples\n",
    "    push!(x_data, x_prev + u_data + sqrt(0.01)*randn()) # State transition\n",
    "    push!(y_data, Φ(x_data[end]) > rand()); # Observation\n",
    "    x_prev = x_data[end]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: Probit not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Probit not defined",
      "",
      "Stacktrace:",
      " [1] macro expansion at .\\none:15 [inlined]",
      " [2] top-level scope at .\\In[2]:15"
     ]
    }
   ],
   "source": [
    "using ForneyLab\n",
    "\n",
    "g = FactorGraph()\n",
    "\n",
    "# State prior\n",
    "@RV x_0 ~ GaussianMeanVariance(0.0, 100.0)\n",
    "\n",
    "x = Vector{Variable}(undef, n_samples)\n",
    "d = Vector{Variable}(undef, n_samples)\n",
    "y = Vector{Variable}(undef, n_samples)\n",
    "x_t_min = x_0\n",
    "for t = 1:n_samples\n",
    "    @RV d[t] ~ GaussianMeanVariance(u_data, 0.01)\n",
    "    @RV x[t] = x_t_min + d[t]\n",
    "    @RV y[t] ~ Probit(x[t])\n",
    "\n",
    "    # Data placeholder\n",
    "    placeholder(y[t], :y, index=t)\n",
    "    \n",
    "    # Reset state for next step\n",
    "    x_t_min = x[t]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm generation\n",
    "\n",
    "With the model defined, we can now generate an EP algorithm. The EP algorithm requires initial messages. To automatically populate the messages array with inital messages, an `init()` function is generated. The EP algorithm is executed by calling `init()` once, and then calling `step!(...)` repeatedly until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = expectationPropagationAlgorithm(x);\n",
    "\n",
    "# println(algo) # Uncomment to inspect algorithm code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(Meta.parse(algo));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = init()\n",
    "marginals = Dict()\n",
    "data = Dict(:y => y_data)\n",
    "\n",
    "n_its = 4*n_samples\n",
    "for i = 1:n_its\n",
    "   step!(data, marginals, messages)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "\n",
    "# Extract posterior statistics\n",
    "m_x = [mean(marginals[:x_*t]) for t = 1:n_samples]\n",
    "v_x = [var(marginals[:x_*t]) for t = 1:n_samples]\n",
    "\n",
    "plot(collect(1:n_samples), x_data, \"k--\", label=\"true x\")\n",
    "plot(collect(1:n_samples), m_x, \"b-\", label=\"estimated x\")\n",
    "fill_between(collect(1:n_samples), m_x-sqrt.(v_x), m_x+sqrt.(v_x), color=\"b\", alpha=0.3);\n",
    "grid(\"on\")\n",
    "xlabel(\"t\")\n",
    "xlim(1, n_samples)\n",
    "ylim(-2, 2)\n",
    "legend(loc=7)\n",
    "\n",
    "ax = gca()\n",
    "ax.twinx()\n",
    "plot(collect(1:n_samples), y_data, \"b*\", label=\"y\")\n",
    "yticks([0.0, 1.0], [\"False\", \"True\"]);\n",
    "ylim(-0.1, 1.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
